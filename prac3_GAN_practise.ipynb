{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST.data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST.data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST.data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST.data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST.data\",one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x):\n",
    "    reuse = len([t for t in tf.global_variables() if t.name.startswith('generator')]) > 0\n",
    "    #print (x.get_shape())\n",
    "    with tf.variable_scope('generator', reuse = reuse):\n",
    "        x = slim.fully_connected(x, 1024)\n",
    "        #print( x)\n",
    "        x = slim.batch_norm(x, activation_fn=tf.nn.relu)\n",
    "        x = slim.fully_connected(x, 7*7*128)\n",
    "        x = slim.batch_norm(x, activation_fn=tf.nn.relu)\n",
    "        x = tf.reshape(x, [-1, 7, 7, 128])\n",
    "        # print '22',tensor.get_shape()\n",
    "        x = slim.conv2d_transpose(x, 64, kernel_size=[4,4], stride=2, activation_fn = None)\n",
    "        #print ('gen',x.get_shape())\n",
    "        x = slim.batch_norm(x, activation_fn = tf.nn.relu)\n",
    "        z = slim.conv2d_transpose(x, 1, kernel_size=[4, 4], stride=2, activation_fn=tf.nn.sigmoid)\n",
    "        #print ('genz',z.get_shape())\n",
    "    return z\n",
    "\n",
    "def leaky_relu(x):\n",
    "     return tf.where(tf.greater(x, 0), x, 0.01 * x)\n",
    "\n",
    "def discriminator(x, num_classes=10, num_cont=2):\n",
    "    reuse = len([t for t in tf.global_variables() if t.name.startswith('discriminator')]) > 0\n",
    "    #print (reuse)\n",
    "    #print (x.get_shape())\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "        x = slim.conv2d(x, num_outputs = 64, kernel_size=[4,4], stride=2, activation_fn=leaky_relu)\n",
    "        x = slim.conv2d(x, num_outputs=128, kernel_size=[4,4], stride=2, activation_fn=leaky_relu)\n",
    "        #print (\"conv2d\",x.get_shape())\n",
    "        x = slim.flatten(x)\n",
    "        shared_tensor = slim.fully_connected(x, num_outputs=1024, activation_fn = leaky_relu)\n",
    "        recog_shared = slim.fully_connected(shared_tensor, num_outputs=128, activation_fn = leaky_relu)\n",
    "        disc = slim.fully_connected(shared_tensor, num_outputs=1, activation_fn=None)\n",
    "        disc = tf.squeeze(disc, -1)\n",
    "        #print (\"disc\",disc.get_shape())#0 or 1\n",
    "        recog_cat = slim.fully_connected(recog_shared, num_outputs=num_classes, activation_fn=None)\n",
    "        recog_cont = slim.fully_connected(recog_shared, num_outputs=num_cont, activation_fn=tf.nn.sigmoid)\n",
    "    return disc, recog_cat, recog_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10   # 获取样本的批次大小32\n",
    "classes_dim = 10  # 10 classes\n",
    "con_dim = 2  # total continuous factor\n",
    "rand_dim = 38  \n",
    "n_input  = 784\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "z_con = tf.random_normal((batch_size, con_dim))#2列\n",
    "z_rand = tf.random_normal((batch_size, rand_dim))#38列\n",
    "z = tf.concat(axis=1, values=[tf.one_hot(y, depth = classes_dim), z_con, z_rand])#50列\n",
    "gen = generator(z)\n",
    "genout= tf.squeeze(gen, -1)\n",
    "\n",
    "\n",
    "# labels for discriminator\n",
    "y_real = tf.ones(batch_size) #真\n",
    "y_fake = tf.zeros(batch_size)#假\n",
    "\n",
    "# 判别器\n",
    "disc_real, class_real, _ = discriminator(x)\n",
    "disc_fake, class_fake, con_fake = discriminator(gen)\n",
    "pred_class = tf.argmax(class_fake, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器 loss\n",
    "loss_d_r = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_real, labels=y_real))\n",
    "loss_d_f = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake, labels=y_fake))\n",
    "loss_d = (loss_d_r + loss_d_f) / 2\n",
    "#print ('loss_d', loss_d.get_shape())\n",
    "# generator loss\n",
    "loss_g = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake, labels=y_real))\n",
    "# categorical factor loss\n",
    "loss_cf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=class_fake, labels=y))#class ok 图片对不上\n",
    "loss_cr = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=class_real, labels=y))#生成的图片与class ok 与输入的class对不上\n",
    "loss_c =(loss_cf + loss_cr) / 2\n",
    "# continuous factor loss\n",
    "loss_con =tf.reduce_mean(tf.square(con_fake-z_con))\n",
    "\n",
    "# 获得各个网络中各自的训练参数\n",
    "t_vars = tf.trainable_variables()\n",
    "d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "g_vars = [var for var in t_vars if 'generator' in var.name]\n",
    "\n",
    "\n",
    "disc_global_step = tf.Variable(0, trainable=False)\n",
    "gen_global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "train_disc = tf.train.AdamOptimizer(0.0001).minimize(loss_d + loss_c + loss_con, var_list = d_vars, global_step = disc_global_step)\n",
    "train_gen = tf.train.AdamOptimizer(0.001).minimize(loss_g + loss_c + loss_con, var_list = g_vars, global_step = gen_global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (10, 10) for Tensor 'Placeholder_1:0', which has shape '(?,)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2148e15cc7a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# Fit training using batch data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0ml_disc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_d_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_disc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_global_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0ml_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_g_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_global_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1111\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1112\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (10, 10) for Tensor 'Placeholder_1:0', which has shape '(?,)'"
     ]
    }
   ],
   "source": [
    "training_epochs = 3\n",
    "display_step = 1\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "        # 遍历全部数据集\n",
    "        for i in range(total_batch):\n",
    "\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)#取数据\n",
    "            feeds = {x: batch_xs, y: batch_ys}\n",
    "\n",
    "            # Fit training using batch data\n",
    "            l_disc, _, l_d_step = sess.run([loss_d, train_disc, disc_global_step],feeds)\n",
    "            l_gen, _, l_g_step = sess.run([loss_g, train_gen, gen_global_step],feeds)\n",
    "\n",
    "        # 显示训练中的详细信息\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f} \".format(l_disc),l_gen)\n",
    "\n",
    "    print(\"完成!\")\n",
    "    \n",
    "    # 测试\n",
    "    print (\"Result:\", loss_d.eval({x: mnist.test.images[:batch_size],y:mnist.test.labels[:batch_size]})\n",
    "                        , loss_g.eval({x: mnist.test.images[:batch_size],y:mnist.test.labels[:batch_size]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-18-ec2eb1d84fb3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-ec2eb1d84fb3>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    show_num = 10\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "     # 根据图片模拟生成图片\n",
    "    show_num = 10\n",
    "    gensimple,d_class,inputx,inputy,con_out = sess.run(\n",
    "        [genout,pred_class,x,y,con_fake], feed_dict={x: mnist.test.images[:batch_size],y: mnist.test.labels[:batch_size]})\n",
    "\n",
    "    f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
    "    for i in range(show_num):\n",
    "        a[0][i].imshow(np.reshape(inputx[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(gensimple[i], (28, 28)))\n",
    "        print(\"d_class\",d_class[i],\"inputy\",inputy[i],\"con_out\",con_out[i])\n",
    "        \n",
    "    plt.draw()\n",
    "    plt.show()  \n",
    "    \n",
    "\n",
    "    my_con=tf.placeholder(tf.float32, [batch_size,2])\n",
    "    myz = tf.concat(axis=1, values=[tf.one_hot(y, depth = classes_dim), my_con, z_rand])\n",
    "    mygen = generator(myz)\n",
    "    mygenout= tf.squeeze(mygen, -1) \n",
    "    \n",
    "    my_con1 = np.ones([10,2])\n",
    "    a = np.linspace(0.0001, 0.99999, 10)\n",
    "    y_input= np.ones([10])\n",
    "    figure = np.zeros((28 * 10, 28 * 10))\n",
    "    my_rand = tf.random_normal((10, rand_dim))\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            my_con1[j][0]=a[i]\n",
    "            my_con1[j][1]=a[j]\n",
    "            y_input[j] = j\n",
    "        mygenoutv =  sess.run(mygenout,feed_dict={y:y_input,my_con:my_con1})\n",
    "        for jj in range(10):\n",
    "            digit = mygenoutv[jj].reshape(28, 28)\n",
    "            figure[i * 28: (i + 1) * 28,\n",
    "                   jj * 28: (jj + 1) * 28] = digit\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
