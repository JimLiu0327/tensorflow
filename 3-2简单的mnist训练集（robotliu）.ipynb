{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.1训练样本###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accuracy0.8293\n",
      "Iter1,Testing Accuracy0.8702\n",
      "Iter2,Testing Accuracy0.8829\n",
      "Iter3,Testing Accuracy0.888\n",
      "Iter4,Testing Accuracy0.8938\n",
      "Iter5,Testing Accuracy0.8968\n",
      "Iter6,Testing Accuracy0.8989\n",
      "Iter7,Testing Accuracy0.9019\n",
      "Iter8,Testing Accuracy0.9035\n",
      "Iter9,Testing Accuracy0.9047\n",
      "Iter10,Testing Accuracy0.9064\n",
      "Iter11,Testing Accuracy0.9071\n",
      "Iter12,Testing Accuracy0.9081\n",
      "Iter13,Testing Accuracy0.9085\n",
      "Iter14,Testing Accuracy0.9101\n",
      "Iter15,Testing Accuracy0.91\n",
      "Iter16,Testing Accuracy0.9112\n",
      "Iter17,Testing Accuracy0.9121\n",
      "Iter18,Testing Accuracy0.9128\n",
      "Iter19,Testing Accuracy0.9136\n",
      "Iter20,Testing Accuracy0.9142\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "\n",
    "#定义每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "\n",
    "#d定义两个placeholder \n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建两个简单的网络\n",
    "Weights = tf.Variable(tf.zeros([784,10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "predicition = tf.nn.softmax(tf.matmul(x,Weights)+ biases)\n",
    "\n",
    "\n",
    "#二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-predicition))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "\n",
    "#initializer初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 结果存放在一个bool型的列表\n",
    "correct_predicition = tf.equal(tf.argmax(y,1),tf.argmax(predicition,1))\n",
    "# argmax返回一维张量中最大值所在的位置\n",
    "\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predicition,tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\" +str(epoch)+\",Testing Accuracy\"+str(acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.2训练#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accuracy0.8303\n",
      "Iter1,Testing Accuracy0.8705\n",
      "Iter2,Testing Accuracy0.8816\n",
      "Iter3,Testing Accuracy0.8882\n",
      "Iter4,Testing Accuracy0.8942\n",
      "Iter5,Testing Accuracy0.8973\n",
      "Iter6,Testing Accuracy0.8998\n",
      "Iter7,Testing Accuracy0.9019\n",
      "Iter8,Testing Accuracy0.9036\n",
      "Iter9,Testing Accuracy0.905\n",
      "Iter10,Testing Accuracy0.9065\n",
      "Iter11,Testing Accuracy0.9069\n",
      "Iter12,Testing Accuracy0.9075\n",
      "Iter13,Testing Accuracy0.909\n",
      "Iter14,Testing Accuracy0.91\n",
      "Iter15,Testing Accuracy0.9102\n",
      "Iter16,Testing Accuracy0.9116\n",
      "Iter17,Testing Accuracy0.9127\n",
      "Iter18,Testing Accuracy0.9137\n",
      "Iter19,Testing Accuracy0.9137\n",
      "Iter20,Testing Accuracy0.9144\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "predicition = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "loss = tf.reduce_mean(tf.square(y-predicition))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "correct_predicition = tf.equal(tf.argmax(y,1),tf.argmax(predicition,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predicition,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\"+str(epoch)+\",Testing Accuracy\"+str(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.3训练#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-d02db4b6ac13>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Iter0,Testing Accuracy0.83\n",
      "Iter1,Testing Accuracy0.871\n",
      "Iter2,Testing Accuracy0.8809\n",
      "Iter3,Testing Accuracy0.8876\n",
      "Iter4,Testing Accuracy0.8932\n",
      "Iter5,Testing Accuracy0.8967\n",
      "Iter6,Testing Accuracy0.8987\n",
      "Iter7,Testing Accuracy0.9019\n",
      "Iter8,Testing Accuracy0.9035\n",
      "Iter9,Testing Accuracy0.9048\n",
      "Iter10,Testing Accuracy0.9065\n",
      "Iter11,Testing Accuracy0.9067\n",
      "Iter12,Testing Accuracy0.9085\n",
      "Iter13,Testing Accuracy0.9089\n",
      "Iter14,Testing Accuracy0.9093\n",
      "Iter15,Testing Accuracy0.9111\n",
      "Iter16,Testing Accuracy0.9118\n",
      "Iter17,Testing Accuracy0.9128\n",
      "Iter18,Testing Accuracy0.9127\n",
      "Iter19,Testing Accuracy0.9134\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "batch_size = 100\n",
    "n_batch= mnist.train.num_examples//batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "# prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "correct_prediction= tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(20):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\"+str(epoch)+\",Testing Accuracy\"+str(acc))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4  No.4训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.要解决的问题：程序一样运行出来的结果不一样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bdd92332c06>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Iter0,testing accuracy0.4086\n",
      "Iter0,testing accuracy0.2753\n",
      "Iter0,testing accuracy0.3068\n",
      "Iter0,testing accuracy0.3195\n",
      "Iter0,testing accuracy0.328\n",
      "Iter0,testing accuracy0.4158\n",
      "Iter0,testing accuracy0.4262\n",
      "Iter0,testing accuracy0.4669\n",
      "Iter0,testing accuracy0.45\n",
      "Iter0,testing accuracy0.4537\n",
      "Iter0,testing accuracy0.4796\n",
      "Iter0,testing accuracy0.4623\n",
      "Iter0,testing accuracy0.4425\n",
      "Iter0,testing accuracy0.4963\n",
      "Iter0,testing accuracy0.4802\n",
      "Iter0,testing accuracy0.5049\n",
      "Iter0,testing accuracy0.5305\n",
      "Iter0,testing accuracy0.5354\n",
      "Iter0,testing accuracy0.536\n",
      "Iter0,testing accuracy0.5577\n",
      "Iter0,testing accuracy0.5563\n",
      "Iter0,testing accuracy0.5473\n",
      "Iter0,testing accuracy0.5329\n",
      "Iter0,testing accuracy0.5613\n",
      "Iter0,testing accuracy0.5556\n",
      "Iter0,testing accuracy0.5984\n",
      "Iter0,testing accuracy0.5952\n",
      "Iter0,testing accuracy0.5998\n",
      "Iter0,testing accuracy0.599\n",
      "Iter0,testing accuracy0.6158\n",
      "Iter0,testing accuracy0.6182\n",
      "Iter0,testing accuracy0.6118\n",
      "Iter0,testing accuracy0.6104\n",
      "Iter0,testing accuracy0.5922\n",
      "Iter0,testing accuracy0.5774\n",
      "Iter0,testing accuracy0.5679\n",
      "Iter0,testing accuracy0.5923\n",
      "Iter0,testing accuracy0.5798\n",
      "Iter0,testing accuracy0.571\n",
      "Iter0,testing accuracy0.5821\n",
      "Iter0,testing accuracy0.5717\n",
      "Iter0,testing accuracy0.5806\n",
      "Iter0,testing accuracy0.5895\n",
      "Iter0,testing accuracy0.6154\n",
      "Iter0,testing accuracy0.6197\n",
      "Iter0,testing accuracy0.6153\n",
      "Iter0,testing accuracy0.6189\n",
      "Iter0,testing accuracy0.6392\n",
      "Iter0,testing accuracy0.631\n",
      "Iter0,testing accuracy0.639\n",
      "Iter0,testing accuracy0.6456\n",
      "Iter0,testing accuracy0.6411\n",
      "Iter0,testing accuracy0.6369\n",
      "Iter0,testing accuracy0.6391\n",
      "Iter0,testing accuracy0.6511\n",
      "Iter0,testing accuracy0.6492\n",
      "Iter0,testing accuracy0.6534\n",
      "Iter0,testing accuracy0.6552\n",
      "Iter0,testing accuracy0.66\n",
      "Iter0,testing accuracy0.6549\n",
      "Iter0,testing accuracy0.6598\n",
      "Iter0,testing accuracy0.6546\n",
      "Iter0,testing accuracy0.6585\n",
      "Iter0,testing accuracy0.6561\n",
      "Iter0,testing accuracy0.6703\n",
      "Iter0,testing accuracy0.6653\n",
      "Iter0,testing accuracy0.6514\n",
      "Iter0,testing accuracy0.6532\n",
      "Iter0,testing accuracy0.6534\n",
      "Iter0,testing accuracy0.655\n",
      "Iter0,testing accuracy0.6551\n",
      "Iter0,testing accuracy0.656\n",
      "Iter0,testing accuracy0.6456\n",
      "Iter0,testing accuracy0.6453\n",
      "Iter0,testing accuracy0.6448\n",
      "Iter0,testing accuracy0.6456\n",
      "Iter0,testing accuracy0.6476\n",
      "Iter0,testing accuracy0.648\n",
      "Iter0,testing accuracy0.6544\n",
      "Iter0,testing accuracy0.6512\n",
      "Iter0,testing accuracy0.6608\n",
      "Iter0,testing accuracy0.6633\n",
      "Iter0,testing accuracy0.6588\n",
      "Iter0,testing accuracy0.6556\n",
      "Iter0,testing accuracy0.6515\n",
      "Iter0,testing accuracy0.6536\n",
      "Iter0,testing accuracy0.6539\n",
      "Iter0,testing accuracy0.6484\n",
      "Iter0,testing accuracy0.6484\n",
      "Iter0,testing accuracy0.6492\n",
      "Iter0,testing accuracy0.6489\n",
      "Iter0,testing accuracy0.6435\n",
      "Iter0,testing accuracy0.6487\n",
      "Iter0,testing accuracy0.6488\n",
      "Iter0,testing accuracy0.6505\n",
      "Iter0,testing accuracy0.6504\n",
      "Iter0,testing accuracy0.644\n",
      "Iter0,testing accuracy0.64\n",
      "Iter0,testing accuracy0.64\n",
      "Iter0,testing accuracy0.6401\n",
      "Iter0,testing accuracy0.6413\n",
      "Iter0,testing accuracy0.6403\n",
      "Iter0,testing accuracy0.6423\n",
      "Iter0,testing accuracy0.6456\n",
      "Iter0,testing accuracy0.6321\n",
      "Iter0,testing accuracy0.6336\n",
      "Iter0,testing accuracy0.6327\n",
      "Iter0,testing accuracy0.638\n",
      "Iter0,testing accuracy0.6414\n",
      "Iter0,testing accuracy0.6347\n",
      "Iter0,testing accuracy0.6383\n",
      "Iter0,testing accuracy0.6432\n",
      "Iter0,testing accuracy0.6424\n",
      "Iter0,testing accuracy0.6427\n",
      "Iter0,testing accuracy0.6462\n",
      "Iter0,testing accuracy0.6438\n",
      "Iter0,testing accuracy0.6426\n",
      "Iter0,testing accuracy0.6427\n",
      "Iter0,testing accuracy0.6492\n",
      "Iter0,testing accuracy0.6498\n",
      "Iter0,testing accuracy0.6489\n",
      "Iter0,testing accuracy0.6504\n",
      "Iter0,testing accuracy0.6558\n",
      "Iter0,testing accuracy0.6536\n",
      "Iter0,testing accuracy0.6567\n",
      "Iter0,testing accuracy0.6571\n",
      "Iter0,testing accuracy0.6616\n",
      "Iter0,testing accuracy0.6588\n",
      "Iter0,testing accuracy0.6555\n",
      "Iter0,testing accuracy0.6612\n",
      "Iter0,testing accuracy0.6643\n",
      "Iter0,testing accuracy0.6656\n",
      "Iter0,testing accuracy0.667\n",
      "Iter0,testing accuracy0.6709\n",
      "Iter0,testing accuracy0.6642\n",
      "Iter0,testing accuracy0.6637\n",
      "Iter0,testing accuracy0.6635\n",
      "Iter0,testing accuracy0.6664\n",
      "Iter0,testing accuracy0.6686\n",
      "Iter0,testing accuracy0.668\n",
      "Iter0,testing accuracy0.6697\n",
      "Iter0,testing accuracy0.6685\n",
      "Iter0,testing accuracy0.6673\n",
      "Iter0,testing accuracy0.6736\n",
      "Iter0,testing accuracy0.6723\n",
      "Iter0,testing accuracy0.6665\n",
      "Iter0,testing accuracy0.6664\n",
      "Iter0,testing accuracy0.6662\n",
      "Iter0,testing accuracy0.6672\n",
      "Iter0,testing accuracy0.669\n",
      "Iter0,testing accuracy0.6704\n",
      "Iter0,testing accuracy0.6712\n",
      "Iter0,testing accuracy0.6714\n",
      "Iter0,testing accuracy0.6737\n",
      "Iter0,testing accuracy0.6731\n",
      "Iter0,testing accuracy0.6748\n",
      "Iter0,testing accuracy0.6742\n",
      "Iter0,testing accuracy0.6751\n",
      "Iter0,testing accuracy0.6778\n",
      "Iter0,testing accuracy0.6772\n",
      "Iter0,testing accuracy0.6799\n",
      "Iter0,testing accuracy0.683\n",
      "Iter0,testing accuracy0.688\n",
      "Iter0,testing accuracy0.6861\n",
      "Iter0,testing accuracy0.6856\n",
      "Iter0,testing accuracy0.6857\n",
      "Iter0,testing accuracy0.6851\n",
      "Iter0,testing accuracy0.6865\n",
      "Iter0,testing accuracy0.6871\n",
      "Iter0,testing accuracy0.6842\n",
      "Iter0,testing accuracy0.6858\n",
      "Iter0,testing accuracy0.6862\n",
      "Iter0,testing accuracy0.6883\n",
      "Iter0,testing accuracy0.6897\n",
      "Iter0,testing accuracy0.6896\n",
      "Iter0,testing accuracy0.6915\n",
      "Iter0,testing accuracy0.6882\n",
      "Iter0,testing accuracy0.6884\n",
      "Iter0,testing accuracy0.6854\n",
      "Iter0,testing accuracy0.6875\n",
      "Iter0,testing accuracy0.6878\n",
      "Iter0,testing accuracy0.6886\n",
      "Iter0,testing accuracy0.6875\n",
      "Iter0,testing accuracy0.6856\n",
      "Iter0,testing accuracy0.6884\n",
      "Iter0,testing accuracy0.6884\n",
      "Iter0,testing accuracy0.6961\n",
      "Iter0,testing accuracy0.6982\n",
      "Iter0,testing accuracy0.7016\n",
      "Iter0,testing accuracy0.7006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8bdd92332c06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iter\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\",testing accuracy\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnist =input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "batch_size =100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys})           \n",
    "            acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print(\"Iter\"+ str(epoch) +\",testing accuracy\" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.5practise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accuracy0.8327\n",
      "Iter1,Testing Accuracy0.8709\n",
      "Iter2,Testing Accuracy0.8819\n",
      "Iter3,Testing Accuracy0.888\n",
      "Iter4,Testing Accuracy0.8939\n",
      "Iter5,Testing Accuracy0.8966\n",
      "Iter6,Testing Accuracy0.9\n",
      "Iter7,Testing Accuracy0.9017\n",
      "Iter8,Testing Accuracy0.9039\n",
      "Iter9,Testing Accuracy0.9046\n",
      "Iter10,Testing Accuracy0.906\n",
      "Iter11,Testing Accuracy0.9072\n",
      "Iter12,Testing Accuracy0.9076\n",
      "Iter13,Testing Accuracy0.9089\n",
      "Iter14,Testing Accuracy0.9098\n",
      "Iter15,Testing Accuracy0.9111\n",
      "Iter16,Testing Accuracy0.9112\n",
      "Iter17,Testing Accuracy0.9119\n",
      "Iter18,Testing Accuracy0.9124\n",
      "Iter19,Testing Accuracy0.9132\n",
      "Iter20,Testing Accuracy0.9139\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\"+ str(epoch) + \",Testing Accuracy\" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.6 practise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题所在：把epoch写成ecoph就会出现循环标号不变的情况\n",
    "显示结果是\n",
    "Extracting MNIST.data\\train-images-idx3-ubyte.gz\n",
    "Extracting MNIST.data\\train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST.data\\t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST.data\\t10k-labels-idx1-ubyte.gz\n",
    "Iter20,testing accuracy0.8332\n",
    "Iter20,testing accuracy0.8701\n",
    "Iter20,testing accuracy0.8821\n",
    "Iter20,testing accuracy0.8886\n",
    "Iter20,testing accuracy0.8934\n",
    "Iter20,testing accuracy0.8975\n",
    "Iter20,testing accuracy0.8991\n",
    "Iter20,testing accuracy0.9017\n",
    "Iter20,testing accuracy0.9034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-05cb726f3eb1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST.data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST.data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST.data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST.data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Iter0,testing accuracy0.8295\n",
      "Iter1,testing accuracy0.8707\n",
      "Iter2,testing accuracy0.8812\n",
      "Iter3,testing accuracy0.8885\n",
      "Iter4,testing accuracy0.8938\n",
      "Iter5,testing accuracy0.897\n",
      "Iter6,testing accuracy0.8999\n",
      "Iter7,testing accuracy0.9018\n",
      "Iter8,testing accuracy0.9033\n",
      "Iter9,testing accuracy0.9052\n",
      "Iter10,testing accuracy0.9055\n",
      "Iter11,testing accuracy0.9072\n",
      "Iter12,testing accuracy0.9089\n",
      "Iter13,testing accuracy0.9081\n",
      "Iter14,testing accuracy0.9095\n",
      "Iter15,testing accuracy0.911\n",
      "Iter16,testing accuracy0.9115\n",
      "Iter17,testing accuracy0.9121\n",
      "Iter18,testing accuracy0.9134\n",
      "Iter19,testing accuracy0.914\n",
      "Iter20,testing accuracy0.9141\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST.data\",one_hot = True)\n",
    "batch_size =100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step =tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "#     for ecoph in range(21):\n",
    "    for epoch for in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})           \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\"+str(epoch)+\",testing accuracy\"+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.7practise运行有问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原因是一个括号没有打上，在23行，是件很可怕的事情。\n",
    "显示的错误结果是在File \"<ipython-input-6-a9d77fa6c21e>\", line 25\n",
    "    print(\"iter\" + str(epoch) + \",testing accuracy\" +str(acc))\n",
    "        ^\n",
    "SyntaxError: invalid syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-a9d77fa6c21e>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-a9d77fa6c21e>\"\u001b[1;36m, line \u001b[1;32m25\u001b[0m\n\u001b[1;33m    print(\"iter\" + str(epoch) + \",testing accuracy\" +str(acc))\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "# loss = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "# train_step = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "# correct_prediction = tf.reduce(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys}) \n",
    "#         acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"iter\" + str(epoch) + \",testing accuracy\" +str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.8practise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现的流程不是很清楚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "# from tensorflow.tourtials.train.mnist as input_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0testing accuracy0.8312\n",
      "Iter1testing accuracy0.8714\n",
      "Iter2testing accuracy0.8822\n",
      "Iter3testing accuracy0.8882\n",
      "Iter4testing accuracy0.8935\n",
      "Iter5testing accuracy0.8964\n",
      "Iter6testing accuracy0.8995\n",
      "Iter7testing accuracy0.9021\n",
      "Iter8testing accuracy0.9031\n",
      "Iter9testing accuracy0.9049\n",
      "Iter10testing accuracy0.906\n",
      "Iter11testing accuracy0.9072\n",
      "Iter12testing accuracy0.908\n",
      "Iter13testing accuracy0.9091\n",
      "Iter14testing accuracy0.91\n",
      "Iter15testing accuracy0.911\n",
      "Iter16testing accuracy0.9116\n",
      "Iter17testing accuracy0.9122\n",
      "Iter18testing accuracy0.9124\n",
      "Iter19testing accuracy0.9127\n",
      "Iter20testing accuracy0.9136\n"
     ]
    }
   ],
   "source": [
    "# mnist = \n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot= True)\n",
    "batch_size =100\n",
    "# n_batch = tourtials.\n",
    "n_batch = mnist.train.num_examples //batch_size\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "Weights = tf.Variable(tf.zeros([784,10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,Weights) + biases)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "\n",
    "# train_step = tf.GradentDescentOptimizer(0.01).minimize(loss)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "\n",
    "# init = tf.global_\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "#             batch_xs,batch_ys = (x:batch_xs,y:batch_ys)\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict= {x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\"+ str(epoch)+ \"testing accuracy\"+ str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.9practise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是括号的问题，报错的代码是【SyntaxError: invalid syntax】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0testingaccuracy0.8295\n",
      "Iter1testingaccuracy0.8705\n",
      "Iter2testingaccuracy0.8807\n",
      "Iter3testingaccuracy0.8875\n",
      "Iter4testingaccuracy0.8939\n",
      "Iter5testingaccuracy0.8974\n",
      "Iter6testingaccuracy0.8994\n",
      "Iter7testingaccuracy0.9021\n",
      "Iter8testingaccuracy0.9038\n",
      "Iter9testingaccuracy0.905\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples //batch_size\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "Weights = tf.Variable(tf.zeros([784,10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,Weights) + biases)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#容易多加括号correct_prediction = tf.equal((tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc =sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}) \n",
    "        print(\"Iter\"+str(epoch)+\"testingaccuracy\"+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.10practise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST.data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST.data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST.data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST.data\\t10k-labels-idx1-ubyte.gz\n",
      "iter0testingacccuracy0.8309\n",
      "iter1testingacccuracy0.8713\n",
      "iter2testingacccuracy0.8822\n",
      "iter3testingacccuracy0.8884\n",
      "iter4testingacccuracy0.8942\n",
      "iter5testingacccuracy0.8964\n",
      "iter6testingacccuracy0.8993\n",
      "iter7testingacccuracy0.9014\n",
      "iter8testingacccuracy0.9032\n",
      "iter9testingacccuracy0.9051\n"
     ]
    }
   ],
   "source": [
    "# 注意(\"MNIST.data,one_hot=True\")\n",
    "mnist = input_data.read_data_sets(\"MNIST.data\",one_hot = True)\n",
    "\n",
    "batch_size =100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "Weights = tf.Variable(tf.zeros([784,10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,Weights) +biases)\n",
    "\n",
    "# loss = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.float32,))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        for batch in range(n_batch):\n",
    "#             batch_xs,batch_ys = \n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"iter\"+str(epoch)+\"testingacccuracy\" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.10 practise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "iter0testingaccuracy0.8329\n",
      "iter1testingaccuracy0.8703\n",
      "iter2testingaccuracy0.8815\n",
      "iter3testingaccuracy0.8881\n",
      "iter4testingaccuracy0.8947\n",
      "iter5testingaccuracy0.8968\n",
      "iter6testingaccuracy0.8993\n",
      "iter7testingaccuracy0.9013\n",
      "iter8testingaccuracy0.9033\n",
      "iter9testingaccuracy0.9049\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "Weights = tf.Variable(tf.zeros([784,10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,Weights)+biases)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "# train_step = \n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        for batch in range (n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"iter\"+str(epoch)+\"testingaccuracy\"+str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.12  practise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples//batch_size\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.softmax(tf.matmul(x,W)+b)\n",
    "                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "训练样本",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
