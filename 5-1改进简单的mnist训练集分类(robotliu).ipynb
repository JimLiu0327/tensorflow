{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.1practise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-7d261ed40e46>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-2-7d261ed40e46>:47: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Iter9,Testing Accuracy0.9165learningrate=0.0006302494\n"
     ]
    }
   ],
   "source": [
    "    #载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "\n",
    "    #每个批次的大小\n",
    "batch_size = 100\n",
    "    #计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "\n",
    "    #define two placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.Variable(0.001,dtype=tf.float32)\n",
    "\n",
    "\n",
    "    #创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784,300],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([300])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([300,100],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([100]) + 0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob )\n",
    "\n",
    "    # W3 = tf.Variable(tf.truncated_normal([1000,500],stddev=0.1))\n",
    "    # b3 = tf.Variable(tf.zeros([500]))\n",
    "    # L3 = tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "    # L3_drop = tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([100,10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L2_drop,W3)+b3)\n",
    "# prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "    # 设置隐藏层\n",
    "    # W = tf.Variable(tf.zeros([784,10]))\n",
    "    # b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    "\n",
    "    #二次代价函数\n",
    "    # loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "    # 使用交叉熵\n",
    "loss =tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "    #shiyong ti度下降法\n",
    "    # train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "train_step = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "\n",
    "\n",
    "    #初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "    #预测\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维\n",
    "    #求准确n\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(10):\n",
    "            sess.run(tf.assign(lr,0.001 * (0.95 ** epoch)))\n",
    "            for batch in range(n_batch):\n",
    "                batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        \n",
    "        learning_rate = sess.run(lr)\n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        print(\"Iter\"+ str(epoch) + \",Testing Accuracy\" + str(train_acc)+\"learningrate=\"+ str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.2训练结果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-66eb5f85fab5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-66eb5f85fab5>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Iter0,Testing Accuracy0.8926         Iter0,Testing Accuracy0.9079\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 使用二次代价函数训练结果           #使用交叉熵结果\n",
    "Iter0,Testing Accuracy0.8926         Iter0,Testing Accuracy0.9079\n",
    "Iter1,Testing Accuracy0.9045         Iter1,Testing Accuracy0.9144\n",
    "Iter2,Testing Accuracy0.9094         Iter2,Testing Accuracy0.9195\n",
    "Iter3,Testing Accuracy0.9132         Iter3,Testing Accuracy0.9224\n",
    "Iter4,Testing Accuracy0.9152         Iter4,Testing Accuracy0.9223\n",
    "Iter5,Testing Accuracy0.9183         Iter5,Testing Accuracy0.9227\n",
    "Iter6,Testing Accuracy0.919I         ter6,Testing Accuracy0.9223\n",
    "Iter7,Testing Accuracy0.9199         Iter7,Testing Accuracy0.9258\n",
    "Iter8,Testing Accuracy0.9202         Iter8,Testing Accuracy0.9253\n",
    "Iter9,Testing Accuracy0.9215         Iter9,Testing Accuracy0.9263\n",
    "Iter10,Testing Accuracy0.921         Iter10,Testing Accuracy0.92548\n",
    "Iter11,Testing Accuracy0.922         Iter11,Testing Accuracy0.92722\n",
    "Iter12,Testing Accuracy0.923         Iter12,Testing Accuracy0.9275\n",
    "Iter13,Testing Accuracy0.924         Iter13,Testing Accuracy0.92681\n",
    "Iter14,Testing Accuracy0.923         Iter14,Testing Accuracy0.92848\n",
    "Iter15,Testing Accuracy0.924         Iter15,Testing Accuracy0.92779\n",
    "Iter16,Testing Accuracy0.924         Iter16,Testing Accuracy0.92651\n",
    "Iter17,Testing Accuracy0.926         Iter17,Testing Accuracy0.9272\n",
    "Iter18,Testing Accuracy0.924         Iter18,Testing Accuracy0.92829\n",
    "Iter19,Testing Accuracy0.924         Iter19,Testing Accuracy0.92689\n",
    "Iter20,Testing Accuracy0.925         Iter20,Testing Accuracy0.92826\n",
    "# 使用adaoptimizer的下降方法         #加入神经隐藏层的方法\n",
    "Iter0,Testing Accuracy0.9247         \n",
    "Iter1,Testing Accuracy0.9254         \n",
    "Iter2,Testing Accuracy0.9278         \n",
    "Iter3,Testing Accuracy0.9282         \n",
    "Iter4,Testing Accuracy0.9292         \n",
    "Iter5,Testing Accuracy0.9308         \n",
    "Iter6,Testing Accuracy0.9286         \n",
    "Iter7,Testing Accuracy0.9312         \n",
    "Iter8,Testing Accuracy0.9325         \n",
    "Iter9,Testing Accuracy0.9328         \n",
    "Iter10,Testing Accuracy0.927         \n",
    "Iter11,Testing Accuracy0.929         \n",
    "Iter12,Testing Accuracy0.931         \n",
    "Iter13,Testing Accuracy0.930         \n",
    "Iter14,Testing Accuracy0.933         \n",
    "Iter15,Testing Accuracy0.931         \n",
    "Iter16,Testing Accuracy0.930         \n",
    "Iter17,Testing Accuracy0.931         \n",
    "Iter18,Testing Accuracy0.932         \n",
    "Iter19,Testing Accuracy0.932         \n",
    "Iter20,Testing Accuracy0.935         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
